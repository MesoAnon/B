{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_map_name = {\n",
    "    \"qwen\": \"Qwen2\",\n",
    "    \"Mistral-7B-Instruct-v0.3\": \"Mistral v0.3\",\n",
    "    \"gemma-7b-it\": \"Gemma 1.1\",\n",
    "    \"Meta-Llama-3-8B-Instruct\": \"Llama 3\",\n",
    "    \"llama3.1\": \"Llama 3.1\",\n",
    "    \"led_tiny\": \"LED-Tiny\",\n",
    "    \"primera_tiny\": \"Primera-Tiny\",\n",
    "    \"led_short\": \"LED-Short\",\n",
    "    \"primera_short\": \"Primera-Short\",\n",
    "    \"led_long\": \"LED-Long\",\n",
    "    \"primera_long\": \"Primera-Long\"\n",
    "}\n",
    "\n",
    "pipeline_map_name = {\n",
    "    \"first5last5_bert\": \"F5L5 + BES\" ,\n",
    "    \"first5last5_textrank\": \"F5L5 + TR\", \n",
    "    \"first5last5\": \"F5L5\",\n",
    "    \"random_selection_bert\": \"RS + BES\",\n",
    "    \"random_selection_textrank\": \"RS + TR\",\n",
    "    \"random_selection\": \"RS\",\n",
    "    \"None\": \"None\"\n",
    "}\n",
    "\n",
    "pipeline_map_name_eurlexsum = {\n",
    "    \"random_selection_bert\": \"BES\",\n",
    "    \"random_selection_textrank\": \"TR\",\n",
    "    \"None\": \"None\"\n",
    "}\n",
    "\n",
    "prompt_type_map = {\n",
    "    \"basic\": \"Basic\",\n",
    "    \"detailed\": \"Policy-Informed\",\n",
    "    \"cod\": \"CoD\",\n",
    "    \"None\": \"None\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "summ_type = \"long\"\n",
    "for result_file in os.listdir():\n",
    "    if summ_type not in result_file:\n",
    "        continue\n",
    "    df = pd.read_pickle(result_file)\n",
    "    if \"qwen\" in df[\"model\"] or \"llama3.1\" in df[\"model\"]:\n",
    "        df[\"selection_type\"] = [\"None\"] * len(df[\"model\"])\n",
    "    if \"primera\" in df[\"model\"][0] or \"led\" in df[\"model\"][0]:\n",
    "        if len(df[\"score_value\"]) == 5:\n",
    "            df[\"prompt_type\"] = [\"None\"] * 5\n",
    "            continue\n",
    "        df[\"model\"] = [df[\"model\"][0]] * 5 + [df[\"model\"][1]] * 5\n",
    "        df[\"prompt_type\"] = [\"None\"] * len(df[\"score_value\"])\n",
    "        df[\"selection_type\"] = [\"random_selection\"] * 5 + [\"first5last5\"] * 5\n",
    "    df = pd.DataFrame(df)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df = df[df[\"score_type\"] != \"mover_score\"]\n",
    "df = df[~df[\"model\"].str.contains(\"mixtral\")]\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"prompt_type\"] = df[\"prompt_type\"].apply(lambda x: x.split(\"_\")[-1])\n",
    "df = df.copy(True).reset_index(drop=True)\n",
    "df = [df.iloc[idx:idx+4].to_numpy() for idx in range(0,len(df),4)]\n",
    "rows = []\n",
    "for row in df:\n",
    "    rows += [[row[0][0], row[0][1], row[0][2], row[0][3], row[1][3], row[2][3], row[3][3]]]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"model\", \"selection_type\", \"prompt_type\", \"R1\", \"R2\", \"RL\", \"BS\"])\n",
    "df[\"model\"] = [model_map_name[name] for name in df[\"model\"]]\n",
    "df[\"selection_type\"] = [pipeline_map_name[name] for name in df[\"selection_type\"]]\n",
    "df[\"prompt_type\"] = [prompt_type_map[name] for name in df[\"prompt_type\"]]\n",
    "\n",
    "from collections import defaultdict\n",
    "latex_dict = defaultdict(dict)\n",
    "for idx, row in df.iterrows():\n",
    "    key = (row[\"selection_type\"] + \" + \" if row[\"selection_type\"] != \"None\" else \"\") + row[\"model\"]\n",
    "\n",
    "    max_value_r1 = str(max(df[df[\"prompt_type\"].str.contains(row[\"prompt_type\"])][\"R1\"]))\n",
    "    max_value_r2 = str(max(df[df[\"prompt_type\"].str.contains(row[\"prompt_type\"])][\"R2\"]))\n",
    "    max_value_rl = str(max(df[df[\"prompt_type\"].str.contains(row[\"prompt_type\"])][\"RL\"]))\n",
    "    max_value_bs = str(round(max(df[df[\"prompt_type\"].str.contains(row[\"prompt_type\"])][\"BS\"]),3))\n",
    "    r1_val = f'\\\\textbf{{{str(row[\"R1\"])}}}' if str(row[\"R1\"]) == max_value_r1 else str(row[\"R1\"])\n",
    "    r2_val = f'\\\\textbf{{{str(row[\"R2\"])}}}' if str(row[\"R2\"]) == max_value_r2 else str(row[\"R2\"])\n",
    "    rl_val = f'\\\\textbf{{{str(row[\"RL\"])}}}' if str(row[\"RL\"]) == max_value_rl else str(row[\"RL\"])\n",
    "    bs_val = f'\\\\textbf{{{str(round(row[\"BS\"],3))}}}' if str(round(row[\"BS\"],3)) == max_value_bs else str(round(row[\"BS\"],3))\n",
    "\n",
    "    latex_dict[key][row[\"prompt_type\"]] = [r1_val, r2_val, rl_val, bs_val]\n",
    "\n",
    "prompt_types = [\"Basic\", \"Policy-Informed\", \"CoD\"]\n",
    "latex_rows_elas = []\n",
    "latex_rows_longcontext = []\n",
    "latex_rows_ablation = []\n",
    "\n",
    "for model in latex_dict.keys():\n",
    "    if \"primera\" in model.lower() or \"led\" in model.lower():\n",
    "        row = model + \" & \" + \" & \".join(latex_dict[model][\"None\"]) + \"\\\\\\\\\"\n",
    "        latex_rows_ablation += [row]\n",
    "    else: \n",
    "        row = model + \" & \"\n",
    "        for prompt in prompt_types:\n",
    "            row += \" & \".join(latex_dict[model][prompt]) + \" & \"\n",
    "        row = row[:-2]\n",
    "        row += \"\\\\\\\\\" \n",
    "        if \"qwen\" in model.lower() or \"llama 3.1\" in model.lower():\n",
    "            latex_rows_longcontext += [row]\n",
    "        else:\n",
    "            latex_rows_elas += [row]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline\n",
      "----------------------\n",
      "F5L5 + BES + Mistral v0.3 & 0.398 & 0.153 & 0.205 & 0.597 & 0.425 & 0.166 & 0.209 & \\textbf{0.602} & 0.381 & 0.133 & 0.197 & 0.542 \\\\\n",
      "RS + BES + Mistral v0.3 & 0.394 & 0.151 & 0.203 & 0.596 & 0.421 & 0.164 & 0.207 & 0.601 & 0.379 & 0.131 & 0.196 & 0.541 \\\\\n",
      "RS + TR + Mistral v0.3 & 0.383 & 0.153 & 0.203 & 0.593 & 0.41 & 0.165 & 0.209 & 0.598 & 0.377 & 0.134 & 0.195 & 0.541 \\\\\n",
      "F5L5 + TR + Mistral v0.3 & 0.383 & 0.154 & 0.203 & 0.594 & 0.411 & 0.167 & 0.209 & 0.599 & 0.38 & 0.137 & 0.197 & 0.542 \\\\\n",
      "F5L5 + BES + Gemma 1.1 & 0.387 & 0.129 & 0.193 & 0.567 & 0.394 & 0.135 & 0.193 & 0.568 & 0.348 & 0.12 & 0.183 & 0.56 \\\\\n",
      "RS + BES + Gemma 1.1 & 0.385 & 0.129 & 0.193 & 0.567 & 0.394 & 0.134 & 0.193 & 0.567 & 0.346 & 0.118 & 0.182 & 0.559 \\\\\n",
      "RS + TR + Gemma 1.1 & 0.383 & 0.131 & 0.196 & 0.566 & 0.392 & 0.134 & 0.197 & 0.566 & 0.357 & 0.128 & 0.189 & 0.564 \\\\\n",
      "F5L5 + TR + Gemma 1.1 & 0.386 & 0.132 & 0.197 & 0.567 & 0.395 & 0.136 & 0.198 & 0.567 & 0.361 & 0.13 & 0.192 & \\textbf{0.566} \\\\\n",
      "F5L5 + BES + Llama 3 & \\textbf{0.435} & 0.166 & \\textbf{0.217} & \\textbf{0.599} & \\textbf{0.433} & \\textbf{0.169} & 0.21 & 0.596 & 0.388 & 0.138 & 0.2 & 0.535 \\\\\n",
      "RS + BES + Llama 3 & 0.432 & 0.163 & 0.215 & 0.598 & \\textbf{0.433} & 0.168 & 0.209 & 0.596 & 0.387 & 0.136 & 0.2 & 0.535 \\\\\n",
      "RS + TR + Llama 3 & 0.418 & 0.157 & 0.213 & 0.593 & 0.428 & 0.168 & \\textbf{0.213} & 0.593 & 0.38 & 0.135 & 0.203 & 0.53 \\\\\n",
      "F5L5 + TR + Llama 3 & 0.418 & 0.158 & 0.212 & 0.593 & 0.428 & 0.168 & \\textbf{0.213} & 0.594 & 0.379 & 0.136 & 0.202 & 0.529 \\\\\n",
      "\n",
      "LongContext\n",
      "----------------------\n",
      "Qwen2 & 0.418 & 0.161 & 0.207 & 0.598 & 0.428 & 0.166 & 0.208 & \\textbf{0.602} & \\textbf{0.392} & 0.137 & 0.201 & 0.549 \\\\\n",
      "Llama 3.1 & 0.426 & \\textbf{0.171} & 0.215 & 0.591 & 0.417 & \\textbf{0.169} & 0.209 & 0.582 & 0.381 & \\textbf{0.142} & \\textbf{0.205} & 0.537 \\\\\n",
      "\n",
      "Ablation\n",
      "----------------------\n",
      "RS + LED-Long & \\textbf{0.437} & \\textbf{0.209} & \\textbf{0.263} & \\textbf{0.624}\\\\\n",
      "F5L5 + LED-Long & 0.433 & 0.208 & \\textbf{0.263} & 0.621\\\\\n",
      "RS + Primera-Long & 0.435 & 0.183 & 0.24 & 0.61\\\\\n",
      "F5L5 + Primera-Long & 0.435 & 0.182 & 0.24 & 0.609\\\\\n"
     ]
    }
   ],
   "source": [
    "print(\"Pipeline\\n----------------------\")\n",
    "print(\"\\n\".join(latex_rows_elas) + \"\\n\")\n",
    "print(\"LongContext\\n----------------------\")\n",
    "print(\"\\n\".join(latex_rows_longcontext) + \"\\n\")\n",
    "print(\"Ablation\\n----------------------\")\n",
    "print(\"\\n\".join(latex_rows_ablation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_type(x):\n",
    "    x = x.split(\"_\")\n",
    "    if len(x) > 2:\n",
    "        x = x[1]\n",
    "    else:\n",
    "        x = x[-1]\n",
    "    return x\n",
    "\n",
    "dfs = []\n",
    "summ_type = \"test\"\n",
    "for result_file in os.listdir():\n",
    "    if summ_type not in result_file or \"eurlexsum\" not in result_file:\n",
    "        continue\n",
    "    df = pd.read_pickle(result_file)\n",
    "    if \"qwen\" in df[\"model\"] or \"llama3.1\" in df[\"model\"]:\n",
    "        df[\"selection_type\"] = [\"None\"] * len(df[\"model\"])\n",
    "    df = pd.DataFrame(df)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df = df[df[\"score_type\"] != \"mover_score\"]\n",
    "df = df[~df[\"model\"].str.contains(\"mixtral\")]\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"prompt_type\"] = df[\"prompt_type\"].apply(lambda x: get_prompt_type(x))\n",
    "df = df.copy(True).reset_index(drop=True)\n",
    "df = [df.iloc[idx:idx+4].to_numpy() for idx in range(0,len(df),4)]\n",
    "rows = []\n",
    "for row in df:\n",
    "    rows += [[row[0][0], row[0][1], row[0][2], row[0][3], row[1][3], row[2][3], row[3][3]]]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"model\", \"selection_type\", \"prompt_type\", \"R1\", \"R2\", \"RL\", \"BS\"])\n",
    "df[\"model\"] = [model_map_name[name] for name in df[\"model\"]]\n",
    "df[\"selection_type\"] = [pipeline_map_name_eurlexsum[name] for name in df[\"selection_type\"]]\n",
    "df[\"prompt_type\"] = [prompt_type_map[name] for name in df[\"prompt_type\"]]\n",
    "\n",
    "from collections import defaultdict\n",
    "latex_dict = defaultdict(dict)\n",
    "for idx, row in df.iterrows():\n",
    "    key = (row[\"selection_type\"] + \" + \" if row[\"selection_type\"] != \"None\" else \"\") + row[\"model\"]\n",
    "\n",
    "    max_value_r1 = str(max(df[df[\"prompt_type\"].str.contains(row[\"prompt_type\"])][\"R1\"]))\n",
    "    max_value_r2 = str(max(df[df[\"prompt_type\"].str.contains(row[\"prompt_type\"])][\"R2\"]))\n",
    "    max_value_rl = str(max(df[df[\"prompt_type\"].str.contains(row[\"prompt_type\"])][\"RL\"]))\n",
    "    max_value_bs = str(round(max(df[df[\"prompt_type\"].str.contains(row[\"prompt_type\"])][\"BS\"]),3))\n",
    "    r1_val = f'\\\\textbf{{{str(row[\"R1\"])}}}' if str(row[\"R1\"]) == max_value_r1 else str(row[\"R1\"])\n",
    "    r2_val = f'\\\\textbf{{{str(row[\"R2\"])}}}' if str(row[\"R2\"]) == max_value_r2 else str(row[\"R2\"])\n",
    "    rl_val = f'\\\\textbf{{{str(row[\"RL\"])}}}' if str(row[\"RL\"]) == max_value_rl else str(row[\"RL\"])\n",
    "    bs_val = f'\\\\textbf{{{str(round(row[\"BS\"],3))}}}' if str(round(row[\"BS\"],3)) == max_value_bs else str(round(row[\"BS\"],3))\n",
    "\n",
    "    latex_dict[key][row[\"prompt_type\"]] = [r1_val, r2_val, rl_val, bs_val]\n",
    "\n",
    "prompt_types = [\"Basic\", \"Policy-Informed\", \"CoD\"]\n",
    "latex_rows_elas = []\n",
    "latex_rows_longcontext = []\n",
    "latex_rows_ablation = []\n",
    "\n",
    "for model in latex_dict.keys():\n",
    "    row = model + \" & \"\n",
    "    for prompt in prompt_types:\n",
    "        row += \" & \".join(latex_dict[model][prompt]) + \" & \"\n",
    "    row = row[:-2]\n",
    "    row += \"\\\\\\\\\" \n",
    "    if \"qwen\" in model.lower() or \"llama 3.1\" in model.lower():\n",
    "        latex_rows_longcontext += [row]\n",
    "    else:\n",
    "        latex_rows_elas += [row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline\n",
      "----------------------\n",
      "BES + Mistral v0.3 & 0.322 & 0.107 & 0.155 & 0.506 & 0.386 & 0.138 & 0.182 & 0.545 & 0.333 & 0.09 & 0.159 & 0.545 \\\\\n",
      "TR + Mistral v0.3 & 0.371 & 0.129 & 0.171 & 0.536 & 0.425 & 0.16 & 0.196 & 0.576 & 0.343 & 0.102 & 0.164 & 0.554 \\\\\n",
      "BES + Gemma 1.1 & 0.265 & 0.087 & 0.138 & 0.505 & 0.307 & 0.105 & 0.155 & 0.523 & 0.216 & 0.064 & 0.117 & 0.498 \\\\\n",
      "TR + Gemma 1.1 & 0.32 & 0.112 & 0.162 & 0.518 & 0.329 & 0.114 & 0.164 & 0.522 & 0.23 & 0.077 & 0.125 & 0.502 \\\\\n",
      "BES + Llama 3 & 0.354 & 0.119 & 0.17 & 0.518 & 0.42 & 0.153 & 0.198 & 0.564 & 0.427 & 0.121 & 0.19 & 0.611 \\\\\n",
      "TR + Llama 3 & 0.384 & 0.141 & 0.184 & 0.535 & 0.442 & 0.169 & 0.206 & 0.578 & 0.425 & 0.131 & 0.201 & 0.601 \\\\\n",
      "\n",
      "LongContext\n",
      "----------------------\n",
      "Llama 3.1 & \\textbf{0.505} & \\textbf{0.211} & \\textbf{0.236} & \\textbf{0.625} & \\textbf{0.51} & \\textbf{0.213} & \\textbf{0.236} & \\textbf{0.633} & \\textbf{0.48} & \\textbf{0.189} & \\textbf{0.228} & \\textbf{0.627} \\\\\n",
      "Qwen2 & 0.478 & 0.187 & 0.212 & 0.596 & 0.463 & 0.171 & 0.202 & 0.597 & 0.313 & 0.109 & 0.158 & 0.538 \\\\\n"
     ]
    }
   ],
   "source": [
    "print(\"Pipeline\\n----------------------\")\n",
    "print(\"\\n\".join(latex_rows_elas) + \"\\n\")\n",
    "print(\"LongContext\\n----------------------\")\n",
    "print(\"\\n\".join(latex_rows_longcontext))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facilex_caselaw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
